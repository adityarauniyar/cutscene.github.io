<!DOCTYPE html>
<html>
<head>
  <link rel = "icon" href = "assets/title_image.png" type = "image/x-icon">
        
  <meta charset="utf-8">
  <meta name="description"
        content="Cutscene: Active vision for Next Best View Planning in outdoor scenes ">
  <meta name="keywords" content="cutscene,FoundVLAD, Foundation Models, Visual Place Recognition, VPR, DINOv2, DINO, SAM">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta property="og:image" content="assets/Thumbnail.png" />        
  <title>Cutscene: Active vision for Next Best View Planning in outdoor scenes </title>

  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>

</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://adityarauniyar.com/">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title"><a href="https://visual-learning.cs.cmu.edu/">16824</a> Course Project: <br>
             Active vision for Next Best View Planning in outdoor scenes.</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://adityarauniyar.com/">Aditya Rauniyar</a>,</span>
              <span class="author-block">
                <a href="https://www.linkedin.com/in/omaralama/">Omar Alama</a>,</span>
              <span class="author-block">
                <a href="https://yuechuanhou.com//">Yuechuan Hou</a>,</span>
              <span class="author-block">
                <a href="https://www.linkedin.com/in/mukul-ganwal/">Mukul Ganwal</a>,</span> 
                <br>
              <!-- <span class="author-block">
              <a href="https://theairlab.org/">Sebastian Scherer</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="https://robotics.iiit.ac.in/">Madhava Krishna</a><sup>2</sup>,</span>  
              <span class="author-block">
              <a href="https://scholar.google.co.in/citations?user=oVS3HHIAAAAJ&hl=en">Sourav Garg</a><sup>4</sup></span> -->
          </div>

          <div class="is-size-6 publication-authors">
            <span class="author-block">
              <a href="https://www.cmu.edu/" style="color: rgb(179, 8, 8);">Carnegie Mellon University</a>
            </span>
          </div>          

          <!-- <div class="is-size-7 publication-authors">
            <span class="author-block">* denotes equal contribution</span>
          </div> -->

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://vcc.tech/UrbanScene3D"
                   class="external-link button is-normal ">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Dataset</span>
                </a>
              </span>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- <section class="hero teaser"> -->
  <!-- <div class="container is-max-desktop"> -->
    <!-- <div class="hero-body"> -->
      <!-- <video id="teaser" autoplay muted loop playsinline height="100%"> -->
        <!-- <img source src="./data/method_viz/Splash GIF.gif" /> -->
        <!-- <video id="dinov2_gardens" autoplay controls muted loop playsinline height="100%"> -->
          <!-- <source src="./data/method_viz/splash_vid_compressed.mp4" -->
                  <!-- type="video/mp4"> -->
        <!-- </video> -->
      <!-- </video> -->
      <!-- <h2 class="subtitle has-text-centered"> -->
        <!-- <span class="coolname">cutscene</span> enables <span>universal visual place recognition (VPR) <i>anywhere</i>, <i>anytime</i> and under <i>anyview</i>.</span>  -->
      <!-- </h2> -->
    <!-- </div> -->
  <!-- </div> -->
<!-- </section> -->

<section class="hero is-small is-light">
  <div class="hero-body">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            In this project, we extend the exploration of autonomous robotic 
            tasks in the context of larger outdoor scenes. Building upon the 
            referenced work, we focus on planning views for these expansive 
            environments, addressing questions related to optimal data collection 
            given a set of reference images. A significant contribution of our 
            approach lies in the introduction of a cutscene augmentation method. 
            This innovative technique involves semantically dividing larger 
            outdoor scenes into smaller components. Our model is then trained 
            to predict uncertainty and RGB values for novel poses within these 
            segmented scenes. This cutscene augmentation method serves a dual 
            purpose. First, it effectively reduces the size of the dataset by 
            a significant percentage, enhancing the efficiency of the training 
            process. Second, and more importantly, it substantially increases 
            the accuracy of novel view predictions. By leveraging this method, 
            our project aims to overcome challenges associated with data 
            collection in large-scale outdoor scenarios, providing a valuable 
            contribution to the broader field of autonomous robotic tasks. 
            Our experiments, using both synthetic and real-world data, 
            demonstrate the effectiveness of our proposed uncertainty-guided 
            approach. The results showcase improved accuracy in scene representations 
            compared to baseline methods, validating the utility and generalizability 
            of our methodology.
          </p>
        </div>
      </div>
    </div>
    </div>
    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <a id="overview_video"></a>
          <iframe
            src="./data/">
          </iframe>
        </div>
      </div>
    </div>
  </div> -->
    <!--/ Paper video. -->
</section>

<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered has-text-centered">
      <div class="column">
        <a id="interactive_demo"></a>
        <h2 class="title is-3">Introduction and Related work</h2>
        <div class="content has-text-justified">
        <p> 
          (WIP) Embodied robotic intelligence relies on active perception 
          and exploration, essential for various applications like 
          robotic manipulation, inspection, and vision-based navigation. 
          The autonomous collection of data plays a pivotal role in 
          scene understanding and subsequent tasks [1]. However, a 
          significant challenge lies in efficiently planning a sequence 
          of views for sensors, ensuring the acquisition of the most 
          valuable information while adhering to platform-specific 
          constraints [2]. Addressing this challenge is crucial for 
          enhancing the training process, particularly in scenarios 
          involving larger scenes.
        </p>
        </div>
      </div>
    </div>

    

    <div class="columns is-centered">

      <div class="column has-text-centered">
        <div class="content">
          <h2 class="title is-4">Multi-UAV Data Gathering</h2>
        <img id="q_image" src = "data/related_work/multi_uav_data_gathering.gif" width="500">
        </div>
      </div>

      <div class="column has-text-centered">
        <div class="content">
          <h2 class="title is-4">Scene Understanding for Manipulation</h2>
          <img id="db_image" src = "data/related_work/nbv_manipulation.gif" width="500">
        </div>
      </div>

      <script src = "data/trajectory_data/hawkins.js"></script>
      <script src = "demo/plot.js"></script>
  
    </div>

    <p></p>
    </div>
</section>

<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="columns is-centered has-text-centered">
      <div class="column">
        <a id="interactive_demo"></a>
        <h2 class="title is-3">Contributions</h2>
        <div class="content has-text-justified">
        <p> 
          (WIP) Describes the three contributions. One sentence each.
        </p>
        </div>
      </div>
    </div>

  <div class="container is-max-desktop">
  <div class="columns is-centered">

  <div class="column has-text-centered">
    <div class="content">
      <h2 class="title is-4">Training on larger outdoor scenes</h2>
      <img id="db_image" src = "data/method_viz/Selection_180_90_30.gif" width="500">
      <!-- <img src = "data/viz_gifs/row3_col3.gif"> -->
    </div>
  </div>

  <div class="column has-text-centered">
    <div class="content">
      <h2 class="title is-4">Hierarchical training strategy</h2>
      <img id="db_image" src = "data/method_viz/cutscene.gif" width="500">
      <!-- <img src = "data/viz_gifs/row3_col3.gif"> -->
    </div>
  </div>

  <div class="column has-text-centered">
    <div class="content">
      <h2 class="title is-4">View planning to gather NBV</h2>
      <img id="db_image" src = "data/method_viz/view_capture_180.gif" width="500">
      <!-- <img src = "data/viz_gifs/row3_col3.gif"> -->
    </div>
  </div>
  </div>

  </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered has-text-centered">
      <div class="column">
        <a id="interactive_demo"></a>
        <h2 class="title is-3">Background</h2>
        <div class="content has-text-justified">
        <p> 
          (WIP) Describes the two major backgrounds on NeRF and PixelNeRF. One sentence each.
        </p>
        </div>
      </div>
    </div>

    

    <div class="columns is-centered">

      <div class="column has-text-centered">
        <div class="content">
          <h2 class="title is-4">NeRF</h2>
          <div class="NeRF-video">
            <iframe width="480" height="270" src="https://www.youtube.com/embed/JuH79E8rdKc?si=AsJpnK8WQT1vKl5q" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>      
          </div>
        </div>
      </div>

      <div class="column has-text-centered">
        <div class="content">
          <h2 class="title is-4">PixelNeRF</h2>
          <div class="PixelNeRF-video">
            <iframe width="480" height="270" src="https://www.youtube.com/embed/voebZx7f32g?si=K-HQnVwn3tHiTIwu" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>          </div>
        </div>
      </div>

      <script src = "data/trajectory_data/hawkins.js"></script>
      <script src = "demo/plot.js"></script>
  
    </div>

    <p></p>
    </div>
</section>


<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="columns is-centered has-text-centered">
      <div class="column">
        <a id="interactive_demo"></a>
        <h2 class="title is-3">Our Approach</h2>
        <div class="content has-text-justified">
        <p> 
          (WIP) Describes the approach from 
          (1) The network architechture, 
          (2) The uncertainity estimation, 
          (3) Uncertainity guided NBV planning.
        </p>
        </div>
      </div>
    </div>

  <div class="container is-max-desktop">
  <div class="columns is-centered">

  <div class="column has-text-centered">
    <div class="content">
      <h2 class="title is-4">Network architechture</h2>
      <img id="db_image" src = "data/method_viz/network_architechture.png" width="500">
      <!-- <img src = "data/viz_gifs/row3_col3.gif"> -->
    </div>
  </div>

  <div class="column has-text-centered">
    <div class="content">
      <h2 class="title is-4">Uncertainity Estimation</h2>
      <img id="db_image" src = "data/method_viz/loss_function.png" width="500">
      <!-- <img src = "data/viz_gifs/row3_col3.gif"> -->
    </div>
  </div>

  <div class="column has-text-centered">
    <div class="content">
      <h2 class="title is-4">NBV planning</h2>
      <img id="db_image" src = "data/method_viz/view_capture_180.gif" width="500">
      <!-- <img src = "data/viz_gifs/row3_col3.gif"> -->
    </div>
  </div>
  </div>

  </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered has-text-centered">
      <div class="column">
        <a id="interactive_demo"></a>
        <h2 class="title is-3">Method</h2>
        <div class="content has-text-justified">
        <p> 
          (WIP) Describes the 
          (1) 30/60/90 without cutscene and with 60-deg cutscene method of training. 
          (2) Uncertainity calculation on uniform sampling and selection for NBV planning.
          One sentence each.
        </p>
        </div>
      </div>
    </div>

    

    <div class="columns is-centered">

      <div class="column has-text-centered">
        <div class="content">
          <h2 class="title is-4">Training on larger outdoor scenes</h2>
          <img id="db_image" src = "data/method_viz/Selection_180_90_30.gif" width="500">
          <!-- <img src = "data/viz_gifs/row3_col3.gif"> -->
        </div>
      </div>

      <div class="column has-text-centered">
        <div class="content">
          <h2 class="title is-4"></h2>
          <div class="content has-text-justified">
            <p> 
              (WIP) Describes the 
              (1) 30/60/90 without cutscene method of training.
            </p>
            </div>
        </div>
      </div>

      <script src = "data/trajectory_data/hawkins.js"></script>
      <script src = "demo/plot.js"></script>
  
    </div>

    <div class="columns is-centered">

      <div class="column has-text-centered">
        <div class="content">
          <h2 class="title is-4">Cutscene Augmentation</h2>
          <img id="db_image" src = "data/method_viz/how_to_cutscene.gif" width="500">
          <!-- <img src = "data/viz_gifs/row3_col3.gif"> -->
        </div>
      </div>

      <div class="column has-text-centered">
        <div class="content">
          <h2 class="title is-4"></h2>
          <div class="content has-text-justified">
            <p> 
              (WIP) Describes the 
              (1) 60-deg cutscene method of training.
            </p>
            </div>
        </div>
      </div>

      <script src = "data/trajectory_data/hawkins.js"></script>
      <script src = "demo/plot.js"></script>
  
    </div>

    <p></p>
    </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered has-text-centered">
      <div class="column">
        <a id="interactive_demo"></a>
        <h2 class="title is-3">Experimental Setup</h2>
        
      </div>
    </div>

    

    <div class="columns is-centered">

      <div class="column has-text-centered">
        <div class="content">
          <div class="NeRF-video">
            <img id="db_image" src = "data/1_1_placeholder.png" width="500">          </div>
        </div>
      </div>

      <div class="column has-text-centered">
        <div class="content">
          <div class="content has-text-justified">
            <p> 
              (WIP) Describes the experimental setup of the model training 
              and planning of views using the model
            </p>
            </div>
        </div>
      </div>

      <script src = "data/trajectory_data/hawkins.js"></script>
      <script src = "demo/plot.js"></script>
  
    </div>

    <p></p>
    </div>
</section>


<section class="hero is-small is-light">
  <div class="hero-body">
  <div class="columns is-centered has-text-centered">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Viewing Range Sensitivity Analysis Results</h2>
      <p>Below, we show qualitative results by fixing the reference views such that
        they are at most 30 degrees apart and fixing the targetted novel view. We then
        vary the model used to make the rgb and uncertainty estimation for this fixed input.
      </p>
    </div>
  </div>

  <div class="container is-max-desktop">

    <div class="column has-text-centered">
        <div class="content">
          <h2 class="title is-4">Reference Images </h2>
          <img id="db_image" src = "data/viewing_range_analysis/scan0_reference_images.jpg" width="500">

          <!-- <img src = "data/viz_gifs/row3_col3.gif"> -->
        </div>
      </div>

      <div class="column has-text-centered">
        <div class="content">
          <h2 class="title is-4">Ground Truth </h2>
          <img id="db_image" src = "data/viewing_range_analysis/scan0_ground_truth.jpg" width="167">

          <!-- <img src = "data/viz_gifs/row3_col3.gif"> -->
        </div>
      </div>

  </div>

  <div class="container is-max-desktop">
    <div class="columns is-centered">

      <div class="column has-text-centered">
        <div class="content">
          <h2 class="title is-4">90deg </h2>
          <img id="db_image" src = "data/viewing_range_analysis/scan0_best_90_rgb_53.jpg" width="500">
          RGB
          <img id="db_image" src = "data/viewing_range_analysis/scan0_best_90_uncertainty_53.jpg" width="500">
          Uncertainty
          <img id="db_image" src = "data/viewing_range_analysis/scan0_best_90_error_53.jpg" width="500">
          Error
          <!-- <img src = "data/viz_gifs/row3_col3.gif"> -->
        </div>
      </div>

      <div class="column has-text-centered">
        <div class="content">
          <h2 class="title is-4">60deg </h2>
          <img id="db_image" src = "data/viewing_range_analysis/scan0_best_60_rgb_53.jpg" width="500">
          RGB
          <img id="db_image" src = "data/viewing_range_analysis/scan0_best_60_uncertainty_53.jpg" width="500">
          Uncertainty
          <img id="db_image" src = "data/viewing_range_analysis/scan0_best_60_error_53.jpg" width="500">
          Error
          <!-- <img src = "data/viz_gifs/row3_col3.gif"> -->
        </div>
      </div>

      <div class="column has-text-centered">
        <div class="content">
          <h2 class="title is-4">30deg</h2>
          <img id="db_image" src = "data/viewing_range_analysis/scan0_best_30_rgb_53.jpg" width="500">
          RGB
          <img id="db_image" src = "data/viewing_range_analysis/scan0_best_30_uncertainty_53.jpg" width="500">
          Uncertainty
          <img id="db_image" src = "data/viewing_range_analysis/scan0_best_30_error_53.jpg" width="500">
          Error
          <!-- <img src = "data/viz_gifs/row3_col3.gif"> -->
        </div>
      </div>
    </div>
    <p>
      We further measure PSNR and SSIM as measures of reconstruction quality
      during training. The curves show the superiority of the quality as you reduce the viewing range.
    </p>
    <div class="columns is-centered">
      <div class="column has-text-centered">
        <div class="content">
          <h2 class="title is-4">PSNR</h2>
          <img id="db_image" src = "data/viewing_range_analysis/scan0_best_90_rgb_53.jpg" width="500">
        </div>
      </div>

      <div class="column has-text-centered">
        <div class="content">
          <h2 class="title is-4">SSIM</h2>
          <img id="db_image" src = "data/viewing_range_analysis/scan0_best_60_rgb_53.jpg" width="500">
        </div>
      </div>
    </div>
    <p>
      The sensitivity analysis we conducted affirms that our framework is
      very sensitive to the viewing range. Having too big of a range will 
      affect the stability of training and the network's capability to learn, while
      having too small of a range would limit the network's novel view estimation.
      Note that even though the reconstruction quality reduces with a bigger viewing
      range, the uncertainty still correlates well with the error which is desirable.
      Thus, such models can still be utilized to estimate the next best view allbeit
      less reliably as the uncertainty predictions would be highly noisy.
      An interesting approach to study would be to incrementally increase the viewing
      range during training to stabilize training while simultaneously pushing 
      the network to expand its viewing range uncertainty estimation capabilities.
      We leave this idea for future work.
    </p>
  </div>

  <br><br><br><br>
  <div class="hero-body">
    <div class="columns is-centered has-text-centered">
      <div class="container is-max-desktop">
        <h2 class="title is-3">Cutscene Augmentation Results</h2>
        <p>
          For qualitative results, we conducted a more challenging analysis
          in which we varied the view 90 degrees in the x and y direction smoothly
          from -45,-45 to +45,+45 centered on the top bird's eye view. We then fixed
          the input views to be [-45,-45],[-35,-35],[+35,+35],[+45,+45].
        </p>
      </div>
    </div>
  
    <div class="container is-max-desktop">
  
      <div class="column has-text-centered">
          <div class="content">
            <h2 class="title is-4">Reference Images </h2>
            <img id="db_image" src = "data/cutscene_animation/town_reference_images.jpg" width="500">
  
            <!-- <img src = "data/viz_gifs/row3_col3.gif"> -->
          </div>
        </div>
  
        <div class="column has-text-centered">
          <div class="content">
            <h2 class="title is-4">Ground Truth </h2>
            <img id="db_image" src = "data/cutscene_animation/town_ground_truth.gif" width="167">
  
            <!-- <img src = "data/viz_gifs/row3_col3.gif"> -->
          </div>
        </div>
  
    </div>
  
    <div class="container is-max-desktop">
      <div class="columns is-centered">
  
        <div class="column has-text-centered">
          <div class="content">
            <h2 class="title is-4">60deg</h2>
            <img id="db_image" src = "data/cutscene_animation/town_60deg.gif" width="500">
            RGB
            <img id="db_image" src = "data/cutscene_animation/town_60deg_uncertainty.gif" width="500">
            Uncertainty
          </div>
        </div>
  
        <div class="column has-text-centered">
          <div class="content">
            <h2 class="title is-4">60deg + Cutscene</h2>
            <img id="db_image" src = "data/cutscene_animation/town_60deg_ca.gif" width="500">
            RGB
            <img id="db_image" src = "data/cutscene_animation/town_60deg_ca_uncertainty.gif" width="500">
            Uncertainty
          </div>
        </div>
  
      </div>
      <p>
        We again measure PSNR and SSIM as measures of reconstruction quality
        during training with cutscene augmentation.
      </p>
      <div class="columns is-centered">
  
        <div class="column has-text-centered">
          <div class="content">
            <h2 class="title is-4">PSNR</h2>
            <img id="db_image" src = "data/viewing_range_analysis/scan0_best_90_rgb_53.jpg" width="500">
          </div>
        </div>
  
        <div class="column has-text-centered">
          <div class="content">
            <h2 class="title is-4">SSIM</h2>
            <img id="db_image" src = "data/viewing_range_analysis/scan0_best_60_rgb_53.jpg" width="500">
          </div>
        </div>
      </div>
      <p>
        The performance improvements introduced by a very simple augmentation technique 
        such as cutscene are significant. Even though the model has never seen more than
        60 degrees of viewing range in a single datapoint. It was able to generalize
        to a broader viewing range (90 degrees) surpassing the baseline. The visualization 
        further serves to show how high uncertainity can hinder the NBV planning capabilities
        of the model. On the right side, we can trivially observe that the cutscene model's uncertainity
        is maximized at the birds eye view [0,0] whearas on the left side for the baseline,
        it is unclear visually which is the next best view as it suffers from high amounts of
        noise.
      </p>
    </div>
    <br><br><br><br>

  <div class="columns is-centered has-text-centered">
    <div class="column">
      <h2 class="title is-3">Planning Results</h2>
      <p>
        Quantitative results on View Planning

      </p>
    </div>
  </div>

  <div class="columns is-centered">

    <div class="column has-text-centered">
        <div class="content">
          <h2 class="title is-4">PSNR </h2>
          <img id="db_image" src = "data/1_1_placeholder.png" width="500">

          <!-- <img src = "data/viz_gifs/row3_col3.gif"> -->
        </div>
      </div>

      <div class="column has-text-centered">
        <div class="content">
          <h2 class="title is-4">SSIM </h2>
          <img id="db_image" src = "data/1_1_placeholder.png" width="500">

          <!-- <img src = "data/viz_gifs/row3_col3.gif"> -->
        </div>
      </div>

  </div>

  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered has-text-centered">
      <div class="column">
        <h2 class="title is-3">Conclusion and Future Work</h2>
        <p></p>
      </div>
    </div>
    
    <div class="columns is-centered">
      <div class="column has-text-centered">
        <div class="content">
          <p>
            (WIP) Concludes the project work and introduces future work.
          </p>
        </div>
      </div>
      
      <div class="column has-text-centered">
        <div class="content">
          
        </div>
      </div>

    </div>

    <p></p>
    </div>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title is-3">BibTeX</h2>
    <pre><code>
      @article{2023cutscene,
        title={Cutscene: Active vision for Next Best View Planning in outdoor scenes},
        author={Rauniyar, Aditya and Alama, Omar and Hou, Yuechuan and Ganwal, Mukul},
        url = {https://adityarauniyar.com/cutscene.github.io/}
        year={2023}
      }
    </code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">
        <img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" />
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website adapted from the Nerfies templates, which is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            If you use the <a href="https://github.com/cutscene/cutscene.github.io">source code</a> of this website,
            please also link back to the <a href="https://github.com/nerfies/nerfies.github.io">Nerfies source code</a> in your footer.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
